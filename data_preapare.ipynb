{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b82c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# 1. to handle the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to visualize the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# To preprocess the data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "# import iterative imputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dba7bae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# load the data from csv file placed locally in our pc\n",
    "df = pd.read_csv('heart_disease_uci.csv')\n",
    "\n",
    "# print the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7589b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    object \n",
      " 3   dataset   920 non-null    object \n",
      " 4   cp        920 non-null    object \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       830 non-null    object \n",
      " 8   restecg   918 non-null    object \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     865 non-null    object \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     611 non-null    object \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      434 non-null    object \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 115.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(920, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b1f33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trestbps',\n",
       " 'chol',\n",
       " 'fbs',\n",
       " 'restecg',\n",
       " 'thalch',\n",
       " 'exang',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'ca',\n",
       " 'thal']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()[df.isnull().sum() > 0].sort_values(ascending=False)\n",
    "missing_data_cols = df.isnull().sum()[df.isnull().sum() > 0].index.tolist()\n",
    "missing_data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776f0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['thal', 'ca', 'slope', 'exang', 'restecg','fbs', 'cp', 'sex', 'num']\n",
    "bool_cols = ['fbs', 'exang']\n",
    "numeric_cols = ['oldpeak', 'thalch', 'chol', 'trestbps', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da2f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "MISSING_TOKEN = \"__MISSING__\"\n",
    "UNK_TOKEN = \"__UNK__\"\n",
    "\n",
    "def fit_label_encoders_per_column(X: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Fit a separate LabelEncoder for each object/category column in X.\n",
    "    Adds MISSING_TOKEN and UNK_TOKEN to the classes for safe transforms later.\n",
    "    \"\"\"\n",
    "    encoders = {}\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object' or str(X[col].dtype).startswith('category'):\n",
    "            le = LabelEncoder()\n",
    "            s = X[col].astype(str).fillna(MISSING_TOKEN)\n",
    "\n",
    "            # Fit on observed values + reserve UNK token\n",
    "            le.fit(pd.Index(s.unique()).append(pd.Index([UNK_TOKEN])))\n",
    "\n",
    "            encoders[col] = le\n",
    "    return encoders\n",
    "\n",
    "def transform_with_encoders(X: pd.DataFrame, encoders: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transform object/category columns using fitted encoders.\n",
    "    Unseen values are mapped to UNK_TOKEN.\n",
    "    \"\"\"\n",
    "    X_out = X.copy()\n",
    "    for col, le in encoders.items():\n",
    "        s = X_out[col].astype(str).fillna(MISSING_TOKEN)\n",
    "\n",
    "        # map unseen categories to UNK_TOKEN\n",
    "        known = set(le.classes_)\n",
    "        s = s.where(s.isin(known), UNK_TOKEN)\n",
    "\n",
    "        X_out[col] = le.transform(s)\n",
    "    return X_out\n",
    "\n",
    "def impute_categorical_missing_data(df, passed_col, missing_data_cols, bool_cols):\n",
    "    df_null = df[df[passed_col].isnull()].copy()\n",
    "    df_not_null = df[df[passed_col].notnull()].copy()\n",
    "\n",
    "    X = df_not_null.drop(passed_col, axis=1).copy()\n",
    "    y = df_not_null[passed_col].copy()\n",
    "\n",
    "    other_missing_cols = [col for col in missing_data_cols if col != passed_col]\n",
    "\n",
    "    # ---- FIX: fit encoders ONCE on df_not_null X and reuse ----\n",
    "    encoders = fit_label_encoders_per_column(X)\n",
    "    X = transform_with_encoders(X, encoders)\n",
    "\n",
    "    # y encoding (if boolean-like column stored as strings)\n",
    "    if passed_col in bool_cols:\n",
    "        y_le = LabelEncoder()\n",
    "        y = y_le.fit_transform(y.astype(str).fillna(MISSING_TOKEN))\n",
    "    else:\n",
    "        # If y is categorical strings, encode it too (recommended)\n",
    "        if y.dtype == 'object' or str(y.dtype).startswith('category'):\n",
    "            y_le = LabelEncoder()\n",
    "            y = y_le.fit_transform(y.astype(str).fillna(MISSING_TOKEN))\n",
    "        else:\n",
    "            y_le = None\n",
    "\n",
    "    # Iterative impute other missing columns inside X (numeric-only expectation)\n",
    "    iterative_imputer = IterativeImputer(\n",
    "        estimator=RandomForestRegressor(random_state=42),\n",
    "        add_indicator=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    for col in other_missing_cols:\n",
    "        if col in X.columns and X[col].isnull().sum() > 0:\n",
    "            X[[col]] = iterative_imputer.fit_transform(X[[col]])[:, [0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    print(f\"The feature '{passed_col}' has been imputed with {round(acc_score*100, 2)} accuracy\\n\")\n",
    "\n",
    "    # ---- Predict missing rows ----\n",
    "    if len(df_null) > 0:\n",
    "        X_null = df_null.drop(passed_col, axis=1).copy()\n",
    "\n",
    "        # IMPORTANT: reuse SAME encoders (no refit!)\n",
    "        X_null = transform_with_encoders(X_null, encoders)\n",
    "\n",
    "        for col in other_missing_cols:\n",
    "            if col in X_null.columns and X_null[col].isnull().sum() > 0:\n",
    "                X_null[[col]] = iterative_imputer.fit_transform(X_null[[col]])[:, [0]]\n",
    "\n",
    "        pred = rf_classifier.predict(X_null)\n",
    "\n",
    "        # decode back if we encoded y\n",
    "        if passed_col in bool_cols:\n",
    "            # if original bool expected: map back\n",
    "            # y_le classes are strings; adapt if you want True/False\n",
    "            # safer: keep as 0/1 for model features\n",
    "            df_null[passed_col] = pred\n",
    "        else:\n",
    "            if y_le is not None:\n",
    "                df_null[passed_col] = y_le.inverse_transform(pred)\n",
    "            else:\n",
    "                df_null[passed_col] = pred\n",
    "\n",
    "    df_combined = pd.concat([df_not_null, df_null], axis=0).sort_index()\n",
    "    return df_combined[passed_col]\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def impute_continuous_missing_data(df, passed_col, missing_data_cols):\n",
    "    df_null = df[df[passed_col].isnull()].copy()\n",
    "    df_not_null = df[df[passed_col].notnull()].copy()\n",
    "\n",
    "    X = df_not_null.drop(passed_col, axis=1).copy()\n",
    "    y = df_not_null[passed_col].copy()\n",
    "\n",
    "    other_missing_cols = [col for col in missing_data_cols if col != passed_col]\n",
    "\n",
    "    # ---- fit encoders ONCE and reuse ----\n",
    "    encoders = fit_label_encoders_per_column(X)\n",
    "    X = transform_with_encoders(X, encoders)\n",
    "\n",
    "    iterative_imputer = IterativeImputer(\n",
    "        estimator=RandomForestRegressor(random_state=42),\n",
    "        add_indicator=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    for col in other_missing_cols:\n",
    "        if col in X.columns and X[col].isnull().sum() > 0:\n",
    "            X[[col]] = iterative_imputer.fit_transform(X[[col]])[:, [0]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    rf_regressor = RandomForestRegressor(random_state=42)\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "    y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)   # squared=False kullanma\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"MAE =\", mae)\n",
    "    print(\"RMSE =\", rmse)\n",
    "    print(\"R2 =\", r2, \"\\n\")\n",
    "\n",
    "    # ---- Predict missing rows ----\n",
    "    if len(df_null) > 0:\n",
    "        X_null = df_null.drop(passed_col, axis=1).copy()\n",
    "        X_null = transform_with_encoders(X_null, encoders)\n",
    "\n",
    "        for col in other_missing_cols:\n",
    "            if col in X_null.columns and X_null[col].isnull().sum() > 0:\n",
    "                X_null[[col]] = iterative_imputer.fit_transform(X_null[[col]])[:, [0]]\n",
    "\n",
    "        df_null[passed_col] = rf_regressor.predict(X_null)\n",
    "\n",
    "    df_combined = pd.concat([df_not_null, df_null], axis=0).sort_index()\n",
    "    return df_combined[passed_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e59cf038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca          611\n",
       "thal        486\n",
       "slope       309\n",
       "fbs          90\n",
       "oldpeak      62\n",
       "trestbps     59\n",
       "thalch       55\n",
       "exang        55\n",
       "chol         30\n",
       "restecg       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()[df.isnull().sum() > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54d0c558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values trestbps : 6.41%\n",
      "MAE = 13.281445086705203\n",
      "RMSE = 17.310355165442367\n",
      "R2 = 0.06440098823305063 \n",
      "\n",
      "Missing Values chol : 3.26%\n",
      "MAE = 44.93601123595506\n",
      "RMSE = 63.67904325600377\n",
      "R2 = 0.6787732491150087 \n",
      "\n",
      "Missing Values fbs : 9.78%\n",
      "The feature 'fbs' has been imputed with 80.12 accuracy\n",
      "\n",
      "Missing Values restecg : 0.22%\n",
      "The feature 'restecg' has been imputed with 66.3 accuracy\n",
      "\n",
      "Missing Values thalch : 5.98%\n",
      "MAE = 16.85670520231214\n",
      "RMSE = 21.749592315626373\n",
      "R2 = 0.31215346312728454 \n",
      "\n",
      "Missing Values exang : 5.98%\n",
      "The feature 'exang' has been imputed with 80.35 accuracy\n",
      "\n",
      "Missing Values oldpeak : 6.74%\n",
      "MAE = 0.5712093023255813\n",
      "RMSE = 0.8086901554006085\n",
      "R2 = 0.37695092112852147 \n",
      "\n",
      "Missing Values slope : 33.59%\n",
      "The feature 'slope' has been imputed with 67.48 accuracy\n",
      "\n",
      "Missing Values ca : 66.41%\n",
      "The feature 'ca' has been imputed with 66.13 accuracy\n",
      "\n",
      "Missing Values thal : 52.83%\n",
      "The feature 'thal' has been imputed with 73.56 accuracy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in missing_data_cols:\n",
    "    print(\"Missing Values\", col, \":\", f\"{round((df[col].isnull().sum()/len(df))*100, 2)}%\")\n",
    "\n",
    "    if col in categorical_cols:\n",
    "        df[col] = impute_categorical_missing_data(\n",
    "            df=df,\n",
    "            passed_col=col,\n",
    "            missing_data_cols=missing_data_cols,\n",
    "            bool_cols=bool_cols\n",
    "        )\n",
    "    elif col in numeric_cols:\n",
    "        df[col] = impute_continuous_missing_data(\n",
    "            df=df,\n",
    "            passed_col=col,\n",
    "            missing_data_cols=missing_data_cols\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b845635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "age         0\n",
       "sex         0\n",
       "dataset     0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalch      0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e00e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>country</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>Restecg</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>st_depression</th>\n",
       "      <th>st_slope_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>thalassemia_type</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical_angina</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1</td>\n",
       "      <td>left_ventricular_hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed_defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0</td>\n",
       "      <td>left_ventricular_hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0</td>\n",
       "      <td>left_ventricular_hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable_defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>atypical_angina</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0</td>\n",
       "      <td>left_ventricular_hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  chest_pain_type    country  resting_blood_pressure  cholesterol  \\\n",
       "0   63    1   typical_angina  Cleveland                   145.0        233.0   \n",
       "1   67    1     asymptomatic  Cleveland                   160.0        286.0   \n",
       "2   67    1     asymptomatic  Cleveland                   120.0        229.0   \n",
       "3   37    1      non-anginal  Cleveland                   130.0        250.0   \n",
       "4   41    0  atypical_angina  Cleveland                   130.0        204.0   \n",
       "\n",
       "  fasting_blood_sugar                       Restecg  max_heart_rate_achieved  \\\n",
       "0                   1  left_ventricular_hypertrophy                    150.0   \n",
       "1                   0  left_ventricular_hypertrophy                    108.0   \n",
       "2                   0  left_ventricular_hypertrophy                    129.0   \n",
       "3                   0                        normal                    187.0   \n",
       "4                   0  left_ventricular_hypertrophy                    172.0   \n",
       "\n",
       "  exercise_induced_angina  st_depression st_slope_type  num_major_vessels  \\\n",
       "0                       0            2.3   downsloping                0.0   \n",
       "1                       1            1.5          flat                3.0   \n",
       "2                       1            2.6          flat                2.0   \n",
       "3                       0            3.5   downsloping                0.0   \n",
       "4                       0            1.4     upsloping                0.0   \n",
       "\n",
       "    thalassemia_type  target  \n",
       "0       fixed_defect       0  \n",
       "1             normal       1  \n",
       "2  reversable_defect       1  \n",
       "3             normal       0  \n",
       "4             normal       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.copy()\n",
    "# In some of the features, there is space will will create problem later on. \n",
    "# So we rename those attributes to handle problems in the future.\n",
    "data['thal'].replace({'fixed defect':'fixed_defect' , 'reversable defect': 'reversable_defect' }, inplace =True)\n",
    "data['cp'].replace({'typical angina':'typical_angina', 'atypical angina': 'atypical_angina' }, inplace =True)\n",
    "data['restecg'].replace({'normal': 'normal' , 'st-t abnormality': 'ST-T_wave_abnormality' , 'lv hypertrophy': 'left_ventricular_hypertrophy' }, inplace =True)\n",
    "\n",
    "# Genrating New Dataset with Less Columns Which Are Necessary .\n",
    "data_1 = data[['age','sex','cp','dataset', 'trestbps', 'chol', 'fbs','restecg' , 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal']].copy()\n",
    "# Some Changes in Target Variable | Only Two Categories (0,1) . 0 for No-Disease , 1 for Disease\n",
    "data_1['target'] = ((data['num'] > 0)*1).copy()\n",
    "# Encoding Sex \n",
    "data_1['sex'] = (data['sex'] == 'Male')*1\n",
    "# Encoding Fbs and exang\n",
    "data_1['fbs'] = (data['fbs'])*1\n",
    "data_1['exang'] = (data['exang'])*1\n",
    "# Renaming COlumns Names.\n",
    "data_1.columns = ['age', 'sex', 'chest_pain_type','country' ,'resting_blood_pressure', \n",
    "              'cholesterol', 'fasting_blood_sugar','Restecg',\n",
    "              'max_heart_rate_achieved', 'exercise_induced_angina', \n",
    "              'st_depression', 'st_slope_type', 'num_major_vessels', \n",
    "              'thalassemia_type', 'target']\n",
    "# Load Data Sample \n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21589cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First 5 rows of the data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Information & Missing Values ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             918 non-null    int64  \n",
      " 1   Sex             918 non-null    object \n",
      " 2   ChestPainType   918 non-null    object \n",
      " 3   RestingBP       918 non-null    int64  \n",
      " 4   Cholesterol     918 non-null    int64  \n",
      " 5   FastingBS       918 non-null    int64  \n",
      " 6   RestingECG      918 non-null    object \n",
      " 7   MaxHR           918 non-null    int64  \n",
      " 8   ExerciseAngina  918 non-null    object \n",
      " 9   Oldpeak         918 non-null    float64\n",
      " 10  ST_Slope        918 non-null    object \n",
      " 11  HeartDisease    918 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 86.2+ KB\n",
      "None\n",
      "\n",
      "--- Statistical Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.510893</td>\n",
       "      <td>132.396514</td>\n",
       "      <td>198.799564</td>\n",
       "      <td>0.233115</td>\n",
       "      <td>136.809368</td>\n",
       "      <td>0.887364</td>\n",
       "      <td>0.553377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.432617</td>\n",
       "      <td>18.514154</td>\n",
       "      <td>109.384145</td>\n",
       "      <td>0.423046</td>\n",
       "      <td>25.460334</td>\n",
       "      <td>1.066570</td>\n",
       "      <td>0.497414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>173.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age   RestingBP  Cholesterol   FastingBS       MaxHR  \\\n",
       "count  918.000000  918.000000   918.000000  918.000000  918.000000   \n",
       "mean    53.510893  132.396514   198.799564    0.233115  136.809368   \n",
       "std      9.432617   18.514154   109.384145    0.423046   25.460334   \n",
       "min     28.000000    0.000000     0.000000    0.000000   60.000000   \n",
       "25%     47.000000  120.000000   173.250000    0.000000  120.000000   \n",
       "50%     54.000000  130.000000   223.000000    0.000000  138.000000   \n",
       "75%     60.000000  140.000000   267.000000    0.000000  156.000000   \n",
       "max     77.000000  200.000000   603.000000    1.000000  202.000000   \n",
       "\n",
       "          Oldpeak  HeartDisease  \n",
       "count  918.000000    918.000000  \n",
       "mean     0.887364      0.553377  \n",
       "std      1.066570      0.497414  \n",
       "min     -2.600000      0.000000  \n",
       "25%      0.000000      0.000000  \n",
       "50%      0.600000      1.000000  \n",
       "75%      1.500000      1.000000  \n",
       "max      6.200000      1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'heart.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display first 5 rows\n",
    "print(\"--- First 5 rows of the data ---\")\n",
    "display(data.head())\n",
    "\n",
    "# Check structure\n",
    "print(\"\\n--- Information & Missing Values ---\")\n",
    "print(data.info())\n",
    "\n",
    "# Statistical Summary\n",
    "print(\"\\n--- Statistical Summary ---\")\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29252ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " age                        0\n",
      "sex                        0\n",
      "chest_pain_type            0\n",
      "country                    0\n",
      "resting_blood_pressure     0\n",
      "cholesterol                0\n",
      "fasting_blood_sugar        0\n",
      "Restecg                    0\n",
      "max_heart_rate_achieved    0\n",
      "exercise_induced_angina    0\n",
      "st_depression              0\n",
      "st_slope_type              0\n",
      "num_major_vessels          0\n",
      "thalassemia_type           0\n",
      "target                     0\n",
      "dtype: int64\n",
      "\n",
      "Shape: (920, 15)\n",
      "Target distribution:\n",
      " target\n",
      "1    509\n",
      "0    411\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved: preprocessed_heart_disease_uci_unscaled.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# data_1 = ...  # senin oluşturduğun son tablo (target dahil) burada hazır\n",
    "\n",
    "# Kategorik ve sayısal sütunları belirle\n",
    "categorical_cols = ['chest_pain_type', 'Restecg', 'st_slope_type', 'thalassemia_type', 'country']\n",
    "numeric_cols = [\n",
    "    'age', 'resting_blood_pressure', 'cholesterol',\n",
    "    'max_heart_rate_achieved', 'st_depression', 'num_major_vessels'\n",
    "]\n",
    "\n",
    "df_processed = data_1.copy()\n",
    "\n",
    "# Label Encoding - Kategorik Değişkenler\n",
    "# (Not: En ideali bunu da CV fold içinde yapmak; şimdilik scaling leakage'ını çözüyoruz.)\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df_processed.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# DO NOT scale numeric columns here (leakage-free requirement)\n",
    "# Scaling will be done after train-test split / inside CV folds.\n",
    "\n",
    "# (Opsiyonel) numeric kolonları float'a çek\n",
    "for col in numeric_cols:\n",
    "    if col in df_processed.columns:\n",
    "        df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Missing values per column:\\n\", df_processed.isnull().sum())\n",
    "print(\"\\nShape:\", df_processed.shape)\n",
    "if 'target' in df_processed.columns:\n",
    "    print(\"Target distribution:\\n\", df_processed['target'].value_counts())\n",
    "\n",
    "# Kaydet\n",
    "output_filename = 'preprocessed_heart_disease_uci_unscaled.csv'\n",
    "df_processed.to_csv(output_filename, index=False)\n",
    "print(f\"\\nSaved: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deb804c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " Age                  0\n",
      "Sex                  0\n",
      "RestingBP            0\n",
      "Cholesterol          0\n",
      "FastingBS            0\n",
      "MaxHR                0\n",
      "ExerciseAngina       0\n",
      "Oldpeak              0\n",
      "HeartDisease         0\n",
      "ChestPainType_ATA    0\n",
      "ChestPainType_NAP    0\n",
      "ChestPainType_TA     0\n",
      "RestingECG_Normal    0\n",
      "RestingECG_ST        0\n",
      "ST_Slope_Flat        0\n",
      "ST_Slope_Up          0\n",
      "dtype: int64\n",
      "\n",
      "Shape: (918, 16)\n",
      "Target distribution:\n",
      " HeartDisease\n",
      "1    508\n",
      "0    410\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved: processed_heart_unscaled.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"heart.csv\")  # örnek: sen zaten data'yı yüklemişsin\n",
    "\n",
    "# --- Preprocessing Pipeline (UNSCALED) ---\n",
    "\n",
    "# 1) Feature groups\n",
    "numeric_features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
    "categorical_features = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "\n",
    "# 2) Copy to avoid modifying original\n",
    "df_processed = data.copy()\n",
    "\n",
    "# 3) Explicit binary encoding (stable)\n",
    "if 'Sex' in df_processed.columns:\n",
    "    df_processed['Sex'] = df_processed['Sex'].map({'M': 1, 'F': 0})\n",
    "\n",
    "if 'ExerciseAngina' in df_processed.columns:\n",
    "    df_processed['ExerciseAngina'] = df_processed['ExerciseAngina'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# 4) One-hot encode remaining categorical string columns (drop_first=True)\n",
    "# We only one-hot encode columns that are still object dtype\n",
    "ohe_cols = [\n",
    "    col for col in categorical_features\n",
    "    if col in df_processed.columns and df_processed[col].dtype == 'object'\n",
    "]\n",
    "df_processed = pd.get_dummies(df_processed, columns=ohe_cols, drop_first=True)\n",
    "\n",
    "# 5) Clean column names\n",
    "df_processed.columns = df_processed.columns.str.strip()\n",
    "\n",
    "# 6) DO NOT scale here (leakage-free requirement)\n",
    "# Scaling (StandardScaler/MinMax) will be done after train-test split / inside CV folds.\n",
    "\n",
    "# 7) Quick sanity checks\n",
    "print(\"Missing values per column:\\n\", df_processed.isnull().sum())\n",
    "print(\"\\nShape:\", df_processed.shape)\n",
    "if 'HeartDisease' in df_processed.columns:\n",
    "    print(\"Target distribution:\\n\", df_processed['HeartDisease'].value_counts())\n",
    "\n",
    "# 8) Save processed dataset (UNSCALED)\n",
    "output_filename = 'processed_heart_unscaled.csv'\n",
    "df_processed.to_csv(output_filename, index=False)\n",
    "print(f\"\\nSaved: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447dbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4dbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35dc1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
